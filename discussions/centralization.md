# Centralization of Resources

## 6/3/2025

Attendance: 5

### Introduction

DDST members and friends discussed the topic of centralization in computer science. Recent advances in LLMs show a trend of reusing the same half dozen LLM models via API calls. Rather than training small language models, a trend has emerged to use prompt engineering and other tools to bend these LLMs to fit many different tasks. Moreover, with advances in quantum computing, we may see a future where advanced computation cannot happen outside specialized locations. The future compute resources may be one of large amounts of data flows to a few central hubs. Cloud platforms like AWS, GCP, Azure, and even NIH's own [biowulf](https://hpc.nih.gov/) cluster are examples of centralized models of compute and data storage.

### Considerations

During the discussion the following topics were raised:

- Privacy, accessibility, and equity concerns
  - Some data is too sensitive to be used on these resources without special agreements. Electronic patient health information (ePHI) especially.
  - These resources can be cost prohibitive for smaller enterprises and organizations.
- Dependence on a few major providers
  - Can suppress innovation and smaller scale competition
- Potential impact on innovation
  - Developers and users are incentivized to innovate on using the models rather than making alternative solutions. Fitting one solution to all problems.

### References

Here are a few resources that came up during the discussion.

- [Empire of AI](https://en.wikipedia.org/wiki/Empire_of_AI) by Karen Hao
- [Taming Silicon Valley](https://mitpress.mit.edu/9780262551069/taming-silicon-valley/) by Gary F. Marcus
- [Gary F. Marcus's Substack](https://garymarcus.substack.com/)
